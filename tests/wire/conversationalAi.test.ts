/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool";
import { ElevenLabsClient } from "../../src/Client";
import * as ElevenLabs from "../../src/api/index";

describe("ConversationalAi", () => {
    test("get_document_rag_indexes (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            indexes: [
                {
                    id: "id",
                    model: "e5_mistral_7b_instruct",
                    status: "created",
                    progress_percentage: 1.1,
                    document_model_index_usage: { used_bytes: 1 },
                },
            ],
        };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.getDocumentRagIndexes("21m00Tcm4TlvDq8ikWAM");
        expect(response).toEqual({
            indexes: [
                {
                    id: "id",
                    model: "e5_mistral_7b_instruct",
                    status: "created",
                    progressPercentage: 1.1,
                    documentModelIndexUsage: {
                        usedBytes: 1,
                    },
                },
            ],
        });
    });

    test("get_document_rag_indexes (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/documentation_id/rag-index")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.getDocumentRagIndexes("documentation_id");
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("delete_document_rag_index (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            model: "e5_mistral_7b_instruct",
            status: "created",
            progress_percentage: 1.1,
            document_model_index_usage: { used_bytes: 1 },
        };
        server
            .mockEndpoint()
            .delete("/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index/21m00Tcm4TlvDq8ikWAM")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.deleteDocumentRagIndex(
            "21m00Tcm4TlvDq8ikWAM",
            "21m00Tcm4TlvDq8ikWAM",
        );
        expect(response).toEqual({
            id: "id",
            model: "e5_mistral_7b_instruct",
            status: "created",
            progressPercentage: 1.1,
            documentModelIndexUsage: {
                usedBytes: 1,
            },
        });
    });

    test("delete_document_rag_index (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .delete("/v1/convai/knowledge-base/documentation_id/rag-index/rag_index_id")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.deleteDocumentRagIndex("documentation_id", "rag_index_id");
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("rag_index_overview (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            total_used_bytes: 1,
            total_max_bytes: 1,
            models: [{ model: "e5_mistral_7b_instruct", used_bytes: 1 }],
        };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/rag-index")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.ragIndexOverview();
        expect(response).toEqual({
            totalUsedBytes: 1,
            totalMaxBytes: 1,
            models: [
                {
                    model: "e5_mistral_7b_instruct",
                    usedBytes: 1,
                },
            ],
        });
    });

    test("rag_index_overview (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .get("/v1/convai/knowledge-base/rag-index")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.ragIndexOverview();
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });
});
