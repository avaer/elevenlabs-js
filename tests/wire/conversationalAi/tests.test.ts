/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../mock-server/MockServerPool";
import { ElevenLabsClient } from "../../../src/Client";
import * as ElevenLabs from "../../../src/api/index";

describe("Tests", () => {
    test("create (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            chat_history: [{ role: "user", time_in_call_secs: 1 }],
            success_condition: "success_condition",
            success_examples: [{ response: "response", type: "success" }],
            failure_examples: [{ response: "response", type: "failure" }],
            name: "name",
        };
        const rawResponseBody = { id: "id" };
        server
            .mockEndpoint()
            .post("/v1/convai/agent-testing/create")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.create({
            chatHistory: [
                {
                    role: "user",
                    timeInCallSecs: 1,
                },
            ],
            successCondition: "success_condition",
            successExamples: [
                {
                    response: "response",
                    type: "success",
                },
            ],
            failureExamples: [
                {
                    response: "response",
                    type: "failure",
                },
            ],
            name: "name",
        });
        expect(response).toEqual({
            id: "id",
        });
    });

    test("create (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            chat_history: [
                {
                    role: "user",
                    agent_metadata: undefined,
                    message: undefined,
                    multivoice_message: undefined,
                    tool_calls: undefined,
                    tool_results: undefined,
                    feedback: undefined,
                    llm_override: undefined,
                    time_in_call_secs: 1,
                    conversation_turn_metrics: undefined,
                    rag_retrieval_info: undefined,
                    llm_usage: undefined,
                    interrupted: undefined,
                    original_message: undefined,
                    source_medium: undefined,
                },
                {
                    role: "user",
                    agent_metadata: undefined,
                    message: undefined,
                    multivoice_message: undefined,
                    tool_calls: undefined,
                    tool_results: undefined,
                    feedback: undefined,
                    llm_override: undefined,
                    time_in_call_secs: 1,
                    conversation_turn_metrics: undefined,
                    rag_retrieval_info: undefined,
                    llm_usage: undefined,
                    interrupted: undefined,
                    original_message: undefined,
                    source_medium: undefined,
                },
            ],
            success_condition: "success_condition",
            success_examples: [
                { response: "response", type: "success" },
                { response: "response", type: "success" },
            ],
            failure_examples: [
                { response: "response", type: "failure" },
                { response: "response", type: "failure" },
            ],
            tool_call_parameters: undefined,
            dynamic_variables: undefined,
            type: undefined,
            from_conversation_metadata: undefined,
            name: "name",
        };
        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .post("/v1/convai/agent-testing/create")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.create({
                chatHistory: [
                    {
                        role: "user",
                        agentMetadata: undefined,
                        message: undefined,
                        multivoiceMessage: undefined,
                        toolCalls: undefined,
                        toolResults: undefined,
                        feedback: undefined,
                        llmOverride: undefined,
                        timeInCallSecs: 1,
                        conversationTurnMetrics: undefined,
                        ragRetrievalInfo: undefined,
                        llmUsage: undefined,
                        interrupted: undefined,
                        originalMessage: undefined,
                        sourceMedium: undefined,
                    },
                    {
                        role: "user",
                        agentMetadata: undefined,
                        message: undefined,
                        multivoiceMessage: undefined,
                        toolCalls: undefined,
                        toolResults: undefined,
                        feedback: undefined,
                        llmOverride: undefined,
                        timeInCallSecs: 1,
                        conversationTurnMetrics: undefined,
                        ragRetrievalInfo: undefined,
                        llmUsage: undefined,
                        interrupted: undefined,
                        originalMessage: undefined,
                        sourceMedium: undefined,
                    },
                ],
                successCondition: "success_condition",
                successExamples: [
                    {
                        response: "response",
                        type: "success",
                    },
                    {
                        response: "response",
                        type: "success",
                    },
                ],
                failureExamples: [
                    {
                        response: "response",
                        type: "failure",
                    },
                    {
                        response: "response",
                        type: "failure",
                    },
                ],
                toolCallParameters: undefined,
                dynamicVariables: undefined,
                type: undefined,
                fromConversationMetadata: undefined,
                name: "name",
            });
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("get (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            chat_history: [
                {
                    role: "user",
                    agent_metadata: { agent_id: "agent_id" },
                    message: "message",
                    multivoice_message: {
                        parts: [{ text: "text", voice_label: undefined, time_in_call_secs: undefined }],
                    },
                    tool_calls: [
                        {
                            request_id: "request_id",
                            tool_name: "tool_name",
                            params_as_json: "params_as_json",
                            tool_has_been_called: true,
                        },
                    ],
                    tool_results: [
                        {
                            request_id: "request_id",
                            tool_name: "tool_name",
                            result_value: "result_value",
                            is_error: true,
                            tool_has_been_called: true,
                        },
                    ],
                    feedback: { score: "like", time_in_call_secs: 1 },
                    llm_override: "llm_override",
                    time_in_call_secs: 1,
                    rag_retrieval_info: {
                        chunks: [{ document_id: "document_id", chunk_id: "chunk_id", vector_distance: 1.1 }],
                        embedding_model: "e5_mistral_7b_instruct",
                        retrieval_query: "retrieval_query",
                        rag_latency_secs: 1.1,
                    },
                    interrupted: true,
                    original_message: "original_message",
                    source_medium: "audio",
                },
            ],
            success_condition: "success_condition",
            success_examples: [{ response: "response", type: "success" }],
            failure_examples: [{ response: "response", type: "failure" }],
            tool_call_parameters: {
                parameters: [{ eval: { type: "anything" }, path: "path" }],
                referenced_tool: { id: "id", type: "system" },
                verify_absence: true,
            },
            dynamic_variables: { key: "value" },
            type: "llm",
            from_conversation_metadata: {
                conversation_id: "conversation_id",
                agent_id: "agent_id",
                workflow_node_id: "workflow_node_id",
                original_agent_reply: [{ role: "user", time_in_call_secs: 1 }],
            },
            id: "id",
            name: "name",
        };
        server
            .mockEndpoint()
            .get("/v1/convai/agent-testing/TeaqRRdTcIfIu2i7BYfT")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.get("TeaqRRdTcIfIu2i7BYfT");
        expect(response).toEqual({
            chatHistory: [
                {
                    role: "user",
                    agentMetadata: {
                        agentId: "agent_id",
                    },
                    message: "message",
                    multivoiceMessage: {
                        parts: [
                            {
                                text: "text",
                                voiceLabel: undefined,
                                timeInCallSecs: undefined,
                            },
                        ],
                    },
                    toolCalls: [
                        {
                            requestId: "request_id",
                            toolName: "tool_name",
                            paramsAsJson: "params_as_json",
                            toolHasBeenCalled: true,
                        },
                    ],
                    toolResults: [
                        {
                            requestId: "request_id",
                            toolName: "tool_name",
                            resultValue: "result_value",
                            isError: true,
                            toolHasBeenCalled: true,
                        },
                    ],
                    feedback: {
                        score: "like",
                        timeInCallSecs: 1,
                    },
                    llmOverride: "llm_override",
                    timeInCallSecs: 1,
                    ragRetrievalInfo: {
                        chunks: [
                            {
                                documentId: "document_id",
                                chunkId: "chunk_id",
                                vectorDistance: 1.1,
                            },
                        ],
                        embeddingModel: "e5_mistral_7b_instruct",
                        retrievalQuery: "retrieval_query",
                        ragLatencySecs: 1.1,
                    },
                    interrupted: true,
                    originalMessage: "original_message",
                    sourceMedium: "audio",
                },
            ],
            successCondition: "success_condition",
            successExamples: [
                {
                    response: "response",
                    type: "success",
                },
            ],
            failureExamples: [
                {
                    response: "response",
                    type: "failure",
                },
            ],
            toolCallParameters: {
                parameters: [
                    {
                        eval: {
                            type: "anything",
                        },
                        path: "path",
                    },
                ],
                referencedTool: {
                    id: "id",
                    type: "system",
                },
                verifyAbsence: true,
            },
            dynamicVariables: {
                key: "value",
            },
            type: "llm",
            fromConversationMetadata: {
                conversationId: "conversation_id",
                agentId: "agent_id",
                workflowNodeId: "workflow_node_id",
                originalAgentReply: [
                    {
                        role: "user",
                        timeInCallSecs: 1,
                    },
                ],
            },
            id: "id",
            name: "name",
        });
    });

    test("get (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .get("/v1/convai/agent-testing/test_id")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.get("test_id");
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("update (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            chat_history: [{ role: "user", time_in_call_secs: 1 }],
            success_condition: "success_condition",
            success_examples: [{ response: "response", type: "success" }],
            failure_examples: [{ response: "response", type: "failure" }],
            name: "name",
        };
        const rawResponseBody = {
            chat_history: [
                {
                    role: "user",
                    agent_metadata: { agent_id: "agent_id" },
                    message: "message",
                    multivoice_message: {
                        parts: [{ text: "text", voice_label: undefined, time_in_call_secs: undefined }],
                    },
                    tool_calls: [
                        {
                            request_id: "request_id",
                            tool_name: "tool_name",
                            params_as_json: "params_as_json",
                            tool_has_been_called: true,
                        },
                    ],
                    tool_results: [
                        {
                            request_id: "request_id",
                            tool_name: "tool_name",
                            result_value: "result_value",
                            is_error: true,
                            tool_has_been_called: true,
                        },
                    ],
                    feedback: { score: "like", time_in_call_secs: 1 },
                    llm_override: "llm_override",
                    time_in_call_secs: 1,
                    rag_retrieval_info: {
                        chunks: [{ document_id: "document_id", chunk_id: "chunk_id", vector_distance: 1.1 }],
                        embedding_model: "e5_mistral_7b_instruct",
                        retrieval_query: "retrieval_query",
                        rag_latency_secs: 1.1,
                    },
                    interrupted: true,
                    original_message: "original_message",
                    source_medium: "audio",
                },
            ],
            success_condition: "success_condition",
            success_examples: [{ response: "response", type: "success" }],
            failure_examples: [{ response: "response", type: "failure" }],
            tool_call_parameters: {
                parameters: [{ eval: { type: "anything" }, path: "path" }],
                referenced_tool: { id: "id", type: "system" },
                verify_absence: true,
            },
            dynamic_variables: { key: "value" },
            type: "llm",
            from_conversation_metadata: {
                conversation_id: "conversation_id",
                agent_id: "agent_id",
                workflow_node_id: "workflow_node_id",
                original_agent_reply: [{ role: "user", time_in_call_secs: 1 }],
            },
            id: "id",
            name: "name",
        };
        server
            .mockEndpoint()
            .put("/v1/convai/agent-testing/TeaqRRdTcIfIu2i7BYfT")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.update("TeaqRRdTcIfIu2i7BYfT", {
            chatHistory: [
                {
                    role: "user",
                    timeInCallSecs: 1,
                },
            ],
            successCondition: "success_condition",
            successExamples: [
                {
                    response: "response",
                    type: "success",
                },
            ],
            failureExamples: [
                {
                    response: "response",
                    type: "failure",
                },
            ],
            name: "name",
        });
        expect(response).toEqual({
            chatHistory: [
                {
                    role: "user",
                    agentMetadata: {
                        agentId: "agent_id",
                    },
                    message: "message",
                    multivoiceMessage: {
                        parts: [
                            {
                                text: "text",
                                voiceLabel: undefined,
                                timeInCallSecs: undefined,
                            },
                        ],
                    },
                    toolCalls: [
                        {
                            requestId: "request_id",
                            toolName: "tool_name",
                            paramsAsJson: "params_as_json",
                            toolHasBeenCalled: true,
                        },
                    ],
                    toolResults: [
                        {
                            requestId: "request_id",
                            toolName: "tool_name",
                            resultValue: "result_value",
                            isError: true,
                            toolHasBeenCalled: true,
                        },
                    ],
                    feedback: {
                        score: "like",
                        timeInCallSecs: 1,
                    },
                    llmOverride: "llm_override",
                    timeInCallSecs: 1,
                    ragRetrievalInfo: {
                        chunks: [
                            {
                                documentId: "document_id",
                                chunkId: "chunk_id",
                                vectorDistance: 1.1,
                            },
                        ],
                        embeddingModel: "e5_mistral_7b_instruct",
                        retrievalQuery: "retrieval_query",
                        ragLatencySecs: 1.1,
                    },
                    interrupted: true,
                    originalMessage: "original_message",
                    sourceMedium: "audio",
                },
            ],
            successCondition: "success_condition",
            successExamples: [
                {
                    response: "response",
                    type: "success",
                },
            ],
            failureExamples: [
                {
                    response: "response",
                    type: "failure",
                },
            ],
            toolCallParameters: {
                parameters: [
                    {
                        eval: {
                            type: "anything",
                        },
                        path: "path",
                    },
                ],
                referencedTool: {
                    id: "id",
                    type: "system",
                },
                verifyAbsence: true,
            },
            dynamicVariables: {
                key: "value",
            },
            type: "llm",
            fromConversationMetadata: {
                conversationId: "conversation_id",
                agentId: "agent_id",
                workflowNodeId: "workflow_node_id",
                originalAgentReply: [
                    {
                        role: "user",
                        timeInCallSecs: 1,
                    },
                ],
            },
            id: "id",
            name: "name",
        });
    });

    test("update (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            chat_history: [
                {
                    role: "user",
                    agent_metadata: undefined,
                    message: undefined,
                    multivoice_message: undefined,
                    tool_calls: undefined,
                    tool_results: undefined,
                    feedback: undefined,
                    llm_override: undefined,
                    time_in_call_secs: 1,
                    conversation_turn_metrics: undefined,
                    rag_retrieval_info: undefined,
                    llm_usage: undefined,
                    interrupted: undefined,
                    original_message: undefined,
                    source_medium: undefined,
                },
                {
                    role: "user",
                    agent_metadata: undefined,
                    message: undefined,
                    multivoice_message: undefined,
                    tool_calls: undefined,
                    tool_results: undefined,
                    feedback: undefined,
                    llm_override: undefined,
                    time_in_call_secs: 1,
                    conversation_turn_metrics: undefined,
                    rag_retrieval_info: undefined,
                    llm_usage: undefined,
                    interrupted: undefined,
                    original_message: undefined,
                    source_medium: undefined,
                },
            ],
            success_condition: "success_condition",
            success_examples: [
                { response: "response", type: "success" },
                { response: "response", type: "success" },
            ],
            failure_examples: [
                { response: "response", type: "failure" },
                { response: "response", type: "failure" },
            ],
            tool_call_parameters: undefined,
            dynamic_variables: undefined,
            type: undefined,
            from_conversation_metadata: undefined,
            name: "name",
        };
        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .put("/v1/convai/agent-testing/test_id")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.update("test_id", {
                chatHistory: [
                    {
                        role: "user",
                        agentMetadata: undefined,
                        message: undefined,
                        multivoiceMessage: undefined,
                        toolCalls: undefined,
                        toolResults: undefined,
                        feedback: undefined,
                        llmOverride: undefined,
                        timeInCallSecs: 1,
                        conversationTurnMetrics: undefined,
                        ragRetrievalInfo: undefined,
                        llmUsage: undefined,
                        interrupted: undefined,
                        originalMessage: undefined,
                        sourceMedium: undefined,
                    },
                    {
                        role: "user",
                        agentMetadata: undefined,
                        message: undefined,
                        multivoiceMessage: undefined,
                        toolCalls: undefined,
                        toolResults: undefined,
                        feedback: undefined,
                        llmOverride: undefined,
                        timeInCallSecs: 1,
                        conversationTurnMetrics: undefined,
                        ragRetrievalInfo: undefined,
                        llmUsage: undefined,
                        interrupted: undefined,
                        originalMessage: undefined,
                        sourceMedium: undefined,
                    },
                ],
                successCondition: "success_condition",
                successExamples: [
                    {
                        response: "response",
                        type: "success",
                    },
                    {
                        response: "response",
                        type: "success",
                    },
                ],
                failureExamples: [
                    {
                        response: "response",
                        type: "failure",
                    },
                    {
                        response: "response",
                        type: "failure",
                    },
                ],
                toolCallParameters: undefined,
                dynamicVariables: undefined,
                type: undefined,
                fromConversationMetadata: undefined,
                name: "name",
            });
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("delete (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .delete("/v1/convai/agent-testing/TeaqRRdTcIfIu2i7BYfT")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.delete("TeaqRRdTcIfIu2i7BYfT");
        expect(response).toEqual({
            key: "value",
        });
    });

    test("delete (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .delete("/v1/convai/agent-testing/test_id")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.delete("test_id");
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("summaries (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = { test_ids: ["test_id_1", "test_id_2"] };
        const rawResponseBody = {
            tests: {
                key: {
                    id: "id",
                    name: "name",
                    access_info: {
                        is_creator: true,
                        creator_name: "John Doe",
                        creator_email: "john.doe@example.com",
                        role: "admin",
                    },
                    created_at_unix_secs: 1,
                    last_updated_at_unix_secs: 1,
                    type: "llm",
                },
            },
        };
        server
            .mockEndpoint()
            .post("/v1/convai/agent-testing/summaries")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.summaries({
            testIds: ["test_id_1", "test_id_2"],
        });
        expect(response).toEqual({
            tests: {
                key: {
                    id: "id",
                    name: "name",
                    accessInfo: {
                        isCreator: true,
                        creatorName: "John Doe",
                        creatorEmail: "john.doe@example.com",
                        role: "admin",
                    },
                    createdAtUnixSecs: 1,
                    lastUpdatedAtUnixSecs: 1,
                    type: "llm",
                },
            },
        });
    });

    test("summaries (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = { test_ids: ["test_ids", "test_ids"] };
        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .post("/v1/convai/agent-testing/summaries")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.summaries({
                testIds: ["test_ids", "test_ids"],
            });
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("list (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            tests: [
                {
                    id: "id",
                    name: "name",
                    access_info: {
                        is_creator: true,
                        creator_name: "John Doe",
                        creator_email: "john.doe@example.com",
                        role: "admin",
                    },
                    created_at_unix_secs: 1,
                    last_updated_at_unix_secs: 1,
                    type: "llm",
                },
            ],
            next_cursor: "next_cursor",
            has_more: true,
        };
        server
            .mockEndpoint()
            .get("/v1/convai/agent-testing")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.tests.list({
            cursor: "cursor",
            pageSize: 1,
            search: "search",
        });
        expect(response).toEqual({
            tests: [
                {
                    id: "id",
                    name: "name",
                    accessInfo: {
                        isCreator: true,
                        creatorName: "John Doe",
                        creatorEmail: "john.doe@example.com",
                        role: "admin",
                    },
                    createdAtUnixSecs: 1,
                    lastUpdatedAtUnixSecs: 1,
                    type: "llm",
                },
            ],
            nextCursor: "next_cursor",
            hasMore: true,
        });
    });

    test("list (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .get("/v1/convai/agent-testing")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.tests.list();
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });
});
