/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../mock-server/MockServerPool";
import { ElevenLabsClient } from "../../../src/Client";
import * as ElevenLabs from "../../../src/api/index";

describe("Settings", () => {
    test("get (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = {
            conversation_initiation_client_data_webhook: {
                url: "https://example.com/webhook",
                request_headers: { "Content-Type": "application/json" },
            },
            webhooks: { post_call_webhook_id: "post_call_webhook_id", send_audio: true },
            can_use_mcp_servers: true,
            rag_retention_period_days: 1,
            default_livekit_stack: "standard",
        };
        server
            .mockEndpoint()
            .get("/v1/convai/settings")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.settings.get();
        expect(response).toEqual({
            conversationInitiationClientDataWebhook: {
                url: "https://example.com/webhook",
                requestHeaders: {
                    "Content-Type": "application/json",
                },
            },
            webhooks: {
                postCallWebhookId: "post_call_webhook_id",
                sendAudio: true,
            },
            canUseMcpServers: true,
            ragRetentionPeriodDays: 1,
            defaultLivekitStack: "standard",
        });
    });

    test("get (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .get("/v1/convai/settings")
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.settings.get();
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });

    test("update (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {};
        const rawResponseBody = {
            conversation_initiation_client_data_webhook: {
                url: "https://example.com/webhook",
                request_headers: { "Content-Type": "application/json" },
            },
            webhooks: { post_call_webhook_id: "post_call_webhook_id", send_audio: true },
            can_use_mcp_servers: true,
            rag_retention_period_days: 1,
            default_livekit_stack: "standard",
        };
        server
            .mockEndpoint()
            .patch("/v1/convai/settings")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.conversationalAi.settings.update();
        expect(response).toEqual({
            conversationInitiationClientDataWebhook: {
                url: "https://example.com/webhook",
                requestHeaders: {
                    "Content-Type": "application/json",
                },
            },
            webhooks: {
                postCallWebhookId: "post_call_webhook_id",
                sendAudio: true,
            },
            canUseMcpServers: true,
            ragRetentionPeriodDays: 1,
            defaultLivekitStack: "standard",
        });
    });

    test("update (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new ElevenLabsClient({ apiKey: "test", environment: server.baseUrl });
        const rawRequestBody = {
            conversation_initiation_client_data_webhook: undefined,
            webhooks: undefined,
            can_use_mcp_servers: undefined,
            rag_retention_period_days: undefined,
            default_livekit_stack: undefined,
        };
        const rawResponseBody = { detail: undefined };
        server
            .mockEndpoint()
            .patch("/v1/convai/settings")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(422)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.conversationalAi.settings.update({
                conversationInitiationClientDataWebhook: undefined,
                webhooks: undefined,
                canUseMcpServers: undefined,
                ragRetentionPeriodDays: undefined,
                defaultLivekitStack: undefined,
            });
        }).rejects.toThrow(ElevenLabs.UnprocessableEntityError);
    });
});
